{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af511c86-ab0b-46bd-922e-453ca47d1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24acccdf-e9be-4e4a-899c-31ca695c7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/joestubbs/coe379L-fa25/main/datasets/unit01/project1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa739347-8ba7-4f32-b0e4-9bd4678d27b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131165, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d6a28-22fc-4911-b2f4-612660294e8f",
   "metadata": {},
   "source": [
    "**1.1 Shape and size:** The data set is 131,165 rows and 12 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b23366-a085-4e66-9998-c15b8a55a36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Animal ID           object\n",
       "Date of Birth       object\n",
       "Name                object\n",
       "DateTime            object\n",
       "MonthYear           object\n",
       "Outcome Type        object\n",
       "Outcome Subtype     object\n",
       "Animal Type         object\n",
       "Sex upon Outcome    object\n",
       "Age upon Outcome    object\n",
       "Breed               object\n",
       "Color               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d406033-f9f6-4778-99b2-1aec04b88d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: Animal ID\n",
      "['A680855' 'A680857' 'A680858' ... 'A672142' 'A675119' 'A678559']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: Date of Birth\n",
      "['5/25/14' '4/22/14' '6/12/14' ... '3/9/25' '2/28/25' '3/19/25']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: Name\n",
      "[nan 'Jenny Tyson' '*Stetson' ... '*Gorgeous George' '*Hen' 'Nahtha']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: DateTime\n",
      "['2014-06-10T00:00:00-05:00' '2014-07-11T00:00:00-05:00'\n",
      " '2014-07-12T00:00:00-05:00' ... '2014-02-08T10:14:00'\n",
      " '2014-02-07T10:14:00' '2014-05-14T08:00:00']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: MonthYear\n",
      "['Jun-14' 'Jul-14' 'Aug-14' 'Sep-14' 'Dec-14' 'Jan-15' 'Feb-15' 'Mar-15'\n",
      " 'Apr-15' 'May-15' 'Jun-15' 'Jul-15' 'Aug-15' 'Sep-15' 'Oct-15' 'Nov-15'\n",
      " 'Dec-15' 'Jan-16' 'Feb-16' 'Mar-16' 'Apr-16' 'May-16' 'Jun-16' 'Jul-16'\n",
      " 'Aug-16' 'Sep-16' 'Oct-16' 'Nov-16' 'Dec-16' 'Jan-17' 'Feb-17' 'Mar-17'\n",
      " 'Apr-17' 'May-17' 'Jun-17' 'Jul-17' 'Aug-17' 'Sep-17' 'Oct-17' 'Nov-17'\n",
      " 'Dec-17' 'Jan-18' 'Feb-18' 'Mar-18' 'Apr-18' 'May-18' 'Jun-18' 'Jul-18'\n",
      " 'Aug-18' 'Sep-18' 'Oct-18' 'Nov-18' 'Dec-18' 'Jan-19' 'Feb-19' 'Mar-19'\n",
      " 'Apr-19' 'May-19' 'Oct-13' 'Nov-13' 'Dec-13' 'Jan-14' 'Feb-14' 'Mar-14'\n",
      " 'Apr-14' 'May-14' 'Oct-14' 'Nov-14' 'Jun-19' 'Jul-19' 'Aug-19' 'Sep-19'\n",
      " 'Oct-19' 'Nov-19' 'Dec-19' 'Jan-20' 'Feb-20' 'Mar-20' 'Apr-20' 'Jun-20'\n",
      " 'Jul-20' 'Aug-20' 'Sep-20' 'Oct-20' 'Nov-20' 'Dec-20' 'Jan-21' 'Feb-21'\n",
      " 'Mar-21' 'Apr-21' 'May-21' 'Jun-21' 'Jul-21' 'Aug-21' 'Sep-21' 'Oct-21'\n",
      " 'Nov-21' 'Dec-21' 'Jan-22' 'Feb-22' 'Mar-22' 'Apr-22' 'May-22' 'Jun-22'\n",
      " 'Jul-22' 'Aug-22' 'Sep-22' 'Oct-22' 'Nov-22' 'Dec-22' 'Jan-23' 'Feb-23'\n",
      " 'Mar-23' 'Apr-23' 'May-23' 'Jun-23' 'Jul-23' 'Aug-23' 'Sep-23' 'Oct-23'\n",
      " 'Nov-23' 'Dec-23' 'Jan-24' 'Feb-24' 'Apr-24' 'May-24' 'Jun-24' 'Jul-24'\n",
      " 'Aug-24' 'Sep-24' 'Oct-24' 'Nov-24' 'Dec-24' 'Jan-25' 'Feb-25' 'Mar-25'\n",
      " 'Apr-25' 'May-25' 'May-20' 'Mar-24']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: Outcome Type\n",
      "['Transfer' 'Adoption' nan]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: Outcome Subtype\n",
      "['Partner' nan 'Foster' 'Offsite' 'SCRP' 'Snr' 'Barn' 'Out State' 'Emer'\n",
      " 'In State']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: Animal Type\n",
      "['Bird' 'Dog' 'Cat' 'Livestock']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: Sex upon Outcome\n",
      "['Unknown' 'Spayed Female' 'Intact Male' 'Intact Female' 'Neutered Male']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: Age upon Outcome\n",
      "['2 weeks' '2 months' '4 weeks' '5 months' '6 months' '1 year' '8 months'\n",
      " '3 weeks' '6 years' '1 weeks' '3 years' '2 years' '1 month' '4 months'\n",
      " '10 months' '5 years' '8 years' '3 months' '9 years' '7 years' '4 years'\n",
      " '4 days' '1 week' '11 months' '7 months' '12 years' '9 months' '10 years'\n",
      " '3 days' '2 days' '11 years' '13 years' '1 day' '20 years' '25 years'\n",
      " '5 weeks' '17 years' '5 days' '14 years' '18 years' '15 years' '16 years'\n",
      " '6 days' '19 years' '30 years']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: Breed\n",
      "['Duck' 'Black Mouth Cur Mix' 'Catbird Mix' ...\n",
      " 'Wirehaired Pointing Griffon' 'Labrador Retriever/Affenpinscher'\n",
      " 'Pekingese/Lhasa Apso']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Column: Color\n",
      "['Yellow/Black' 'Brown/Black' 'Brown' 'Black/White' 'Black' 'White'\n",
      " 'Brown/White' 'Tan' 'Blue Tabby' 'Cream' 'Gold' 'Red' 'Fawn/White'\n",
      " 'White/Gray' 'Torbie' 'Sable' 'Yellow' 'White/Black' 'White/Chocolate'\n",
      " 'Cream/Black' 'White/Brown' 'Chocolate/White' 'White/Red Tick'\n",
      " 'White/Brown Brindle' 'Buff/Gray' 'Black/Tan' 'Blue Merle/Black'\n",
      " 'Chocolate' 'White/Tan' 'Tan/White' 'Pink' 'Tricolor' 'Red/White'\n",
      " 'Calico' 'Brown Tabby/White' 'Brown Brindle' 'Blue Tick/Black'\n",
      " 'Blue/White' 'Black/Brown' 'Green/Blue' 'Brown Tabby' 'Orange Tabby'\n",
      " 'Tortie' 'Blue Merle' 'Orange/Tan' 'White/White' 'Orange Tabby/White'\n",
      " 'Cream Tabby' 'Cream Tabby/White' 'Lilac Point' 'Lynx Point' 'Black/Buff'\n",
      " 'White/Cream Tabby' 'Seal Point' 'Blue Merle/White' 'Brown Brindle/White'\n",
      " 'Sable/Buff' 'Chocolate/Tan' 'Brown/Brown' 'Tortie Point'\n",
      " 'Orange/Orange Tabby' 'Black Tabby/White' 'Blue Tabby/White' 'Blue'\n",
      " 'Buff' 'White/Red' 'Fawn/Black' 'Blue/Tan' 'Red/Tan' 'Black Brindle'\n",
      " 'White/Blue Tick' 'White/Blue' 'Red/Black' 'Tricolor/Brown Merle'\n",
      " 'Seal Point/Brown' 'Tan/Black' 'Flame Point' 'Brown Merle'\n",
      " 'White/Blue Merle' 'Brown Merle/Tan' 'Gray/Silver' 'White/Tricolor'\n",
      " 'Black/Brown Brindle' 'Brown/Tan' 'Buff/White' 'Black/Red' 'Yellow/White'\n",
      " 'Fawn' 'Gray' 'Sable/White' 'Cream/White' 'Tortie Point/White'\n",
      " 'Tricolor/White' 'Blue/Tricolor' 'Blue/Black' 'Gray Tabby/White'\n",
      " 'White/Brown Tabby' 'Black Smoke/White' 'Brown Brindle/Black'\n",
      " 'Gray/Brown' 'White/Tortie' 'Gold/Cream' 'Orange' 'Red Tick/White'\n",
      " 'Tortie/White' 'White/Orange Tabby' 'Gray Tabby' 'Black Tabby'\n",
      " 'Silver/Brown' 'Black/Tricolor' 'Torbie/Gray' 'Gold/White' 'Silver/Black'\n",
      " 'Black/Black Brindle' 'White/Orange' 'Blue Tiger/White' 'Gray/White'\n",
      " 'Black Brindle/White' 'Black/Cream' 'Silver/Red' 'Black/Black'\n",
      " 'Liver/White' 'Brown/Red Tick' 'Red Merle' 'White/Yellow'\n",
      " 'Brown Merle/White' 'Black/Blue Tick' 'Orange Tabby/Cream' 'Torbie/White'\n",
      " 'Black/Gray' 'Agouti' 'Lynx Point/White' 'Tricolor/Brown' 'Gray/Gray'\n",
      " 'Gray Tabby/Black' 'Brown/Tricolor' 'Brown Tiger' 'Gray/Blue'\n",
      " 'Silver Tabby/White' 'Tan/Tan' 'Red/Cream' 'Silver Tabby' 'Calico/White'\n",
      " 'Brown Tabby/Black' 'White/Black Tabby' 'Brown/Yellow' 'Blue Point/White'\n",
      " 'White/Cream' 'Orange/White' 'Blue Point' 'Liver/Cream' 'Silver'\n",
      " 'Tan/Cream' 'Red Merle/White' 'White/Buff' 'Black/Blue Merle'\n",
      " 'Calico Point/White' 'White/Blue Tabby' 'Black Smoke' 'Buff/Tan'\n",
      " 'Blue Merle/Tan' 'Liver/Brown Brindle' 'Gray/Tan' 'Chocolate/Black Smoke'\n",
      " 'Blue Merle/Cream' 'Black/Black Smoke' 'Tan/Brown' 'Gold/Buff' 'Apricot'\n",
      " 'Red/Buff' 'Brown Tabby/Orange' 'Calico Point' 'White/Red Merle'\n",
      " 'Black/Silver' 'Blue Merle/Brown' 'Blue Cream' 'Buff/Black' 'Gray/Black'\n",
      " 'Sable/Tan' 'Yellow/Tan' 'Red Tick/Brown Merle' 'Cream/Tan'\n",
      " 'Red Tick/Tan' 'Green' 'Red Tick' 'Apricot/White' 'Tan/Silver'\n",
      " 'Silver/Tan' 'Brown Brindle/Blue Cream' 'Calico/Brown Tabby'\n",
      " 'Red Merle/Black' 'White/Brown Merle' 'Blue Tick/Brown' 'Blue Tick/White'\n",
      " 'Black/Chocolate' 'Brown Tabby/Tortie' 'Seal Point/White'\n",
      " 'Tricolor/Chocolate' 'Chocolate Point' 'Lynx Point/Brown Tabby'\n",
      " 'Gray/Cream' 'Blue Cream/Blue Tabby' 'Lynx Point/Gray Tabby'\n",
      " 'Blue Tabby/Blue Cream' 'Sable/Black' 'Tan/Buff' 'White/Gray Tabby'\n",
      " 'Red/Tricolor' 'Tortie/Blue Cream' 'Tan/Gray' 'Blue Tick'\n",
      " 'White/Yellow Brindle' 'Sable/Red Merle' 'White/Black Brindle' 'Tan/Red'\n",
      " 'White/Apricot' 'Blue/Brown Brindle' 'Blue Tick/Tan' 'Blue Cream/Buff'\n",
      " 'Calico/Blue Cream' 'White/Brown Tiger' 'Yellow Brindle/White'\n",
      " 'Cream/Red' 'Chocolate/Red' 'Tricolor/Blue Merle' 'White/Silver'\n",
      " 'Brown Merle/Black' 'Chocolate Point/White' 'Blue Smoke/Brown'\n",
      " 'White/Blue Cream' 'Ruddy/Cream' 'Chocolate/Brown' 'Blue Merle/Tricolor'\n",
      " 'Brown/Red' 'Tricolor/Tan' 'Red/Brown' 'Fawn/Blue' 'Black Smoke/Black'\n",
      " 'Tan/Yellow' 'Sable/Brown' 'Black/Brown Merle' 'White/Pink' 'Brown/Gray'\n",
      " 'Yellow Brindle' 'Chocolate/Tricolor' 'Brown/Red Merle' 'Red Tick/Orange'\n",
      " 'Blue Tick/Brown Brindle' 'Gold/Black' 'Black/Blue' 'Blue Tick/Red Tick'\n",
      " 'Calico/Blue Tabby' 'Gold/Yellow' 'Fawn/Brown' 'Tan/Apricot'\n",
      " 'Red/Red Merle' 'Blue Merle/Red' 'Liver Tick/White' 'Liver/Tan'\n",
      " 'Chocolate/Black' 'Tortie/Orange' 'Calico/Orange Tabby'\n",
      " 'Brown Tabby/Gray Tabby' 'Gray/Yellow' 'Cream/Gray' 'Red/Red Tick'\n",
      " 'Red Tick/Black' 'Tan/Tricolor' 'Black Brindle/Brown' 'Tortie/Black'\n",
      " 'Red Tick/Blue Tick' 'Green/Yellow' 'Silver Lynx Point' 'Gold/Tan'\n",
      " 'Brown/Chocolate' 'Agouti/Brown Tabby' 'Green/White' 'Buff/Brown'\n",
      " 'White/Liver' 'Brown/Silver' 'Black/Orange' 'Blue/Gray' 'Buff/Yellow'\n",
      " 'Silver Tabby/Black' 'Red/Silver' 'Gray/Gold' 'Tricolor/Black'\n",
      " 'Brown Brindle/Red Tick' 'Blue/Cream' 'Chocolate/Brown Merle'\n",
      " 'White/Lynx Point' 'Red Tick/Red' 'Cream/Orange' 'Brown Tabby/Brown'\n",
      " 'Chocolate/Brown Brindle' 'White/Black Smoke' 'Cream/Red Tick'\n",
      " 'Red Tick/Brown' 'Chocolate/Cream' 'Chocolate/Red Tick'\n",
      " 'White/Flame Point' 'Blue Tabby/Cream' 'Black Smoke/Brown Tabby'\n",
      " 'Brown/Cream' 'Calico/Black' 'Blue Merle/Red Merle'\n",
      " 'Brown Tabby/Black Brindle' 'Blue Tiger' 'Fawn/Brown Brindle' 'Red/Blue'\n",
      " 'Torbie/Blue Cream' 'Blue Tick/Red' 'White/Seal Point'\n",
      " 'Black/Yellow Brindle' 'Fawn/Tan' 'Blue Cream/Blue Tiger'\n",
      " 'Blue Merle/Blue Merle' 'Yellow Brindle/Blue' 'Black/Green' 'Red/Green'\n",
      " 'Brown Brindle/Blue' 'Tricolor/Blue' 'Blue/Calico' 'Brown Brindle/Brown'\n",
      " 'Blue/Brown' 'Silver/White' 'Brown Brindle/Brown Brindle' 'Liver Tick'\n",
      " 'Blue Cream/Tortie' 'Sable/Cream' 'Liver' 'Brown Tiger/White'\n",
      " 'Blue Merle/Brown Brindle' 'Sable/Red' 'Calico/Tricolor' 'Chocolate/Gold'\n",
      " 'Silver/Chocolate' 'Blue/Yellow Brindle' 'Calico/Brown' 'Gray/Red'\n",
      " 'Brown/Buff' 'Gray/Buff' 'Tan/Blue' 'Brown Tabby/Gray' 'Fawn/Gray'\n",
      " 'Torbie/Brown' 'Fawn/Tricolor' 'Fawn/Chocolate' 'Blue Smoke/White'\n",
      " 'Red/Gold' 'Black/Tortie' 'Buff/Red' 'White/Chocolate Point' 'Blue Smoke'\n",
      " 'Red/Red' 'Blue Tabby/Tan' 'Red/Gray' 'Brown Brindle/Blue Tick'\n",
      " 'Black Tiger/White' 'Tricolor/Calico' 'Blue/Tortie' 'Orange Tabby/Black'\n",
      " 'Orange Tabby/Tortie Point' 'Tortie/Calico' 'Brown Brindle/Tan'\n",
      " 'Black/Silver Tabby' 'Brown/Black Tabby' 'Tortie/Brown' 'Blue/Orange'\n",
      " 'Tan/Red Tick' 'Brown Merle/Blue Merle' 'White/Calico'\n",
      " 'Brown Merle/Brown' 'Black/Black Tabby' 'Gray/Tricolor'\n",
      " 'Tortie Point/Lynx Point' 'Black/Yellow' 'Silver/Cream'\n",
      " 'Tortie/Black Smoke' 'Blue Cream/White' 'Blue/Yellow' 'Sable/Gray'\n",
      " 'Cream/Brown' 'Apricot/Brown' 'Blue Tabby/Orange' 'Lilac Point/White'\n",
      " 'Green/Gray' 'Chocolate/Brown Tabby' 'Tortie/Blue' 'Gray/Tortie'\n",
      " 'Silver/Gray' 'Agouti/White' 'Brown Tabby/Blue'\n",
      " 'Brown Tabby/Orange Tabby' 'Flame Point/Cream' 'Torbie/Blue Tabby'\n",
      " 'Brown/Green' 'Chocolate/Yellow' 'Torbie/Brown Tabby' 'Black/Gold'\n",
      " 'Black/Brown Tabby' 'Flame Point/White' 'Yellow/Orange' 'Cream/Silver'\n",
      " 'Lynx Point/Tan' 'Orange Tabby/Brown' 'Brown Tabby/Brown Tabby'\n",
      " 'Orange Tabby/Orange' 'Orange Tabby/Orange Tabby' 'Blue/Blue' 'Gold/Gold'\n",
      " 'Black Smoke/Blue Tick' 'Cream/Seal Point' 'Gold/Brown' 'Calico/Calico'\n",
      " 'Red/Yellow' 'Tortie/Blue Tabby' 'Cream Tabby/Cream Tabby'\n",
      " 'Black/Gray Tabby' 'Silver Lynx Point/Gray' 'Lynx Point/Tortie Point'\n",
      " 'Blue/Silver' 'Seal Point/Gray' 'White/Calico Point' 'Brown Tabby/Cream'\n",
      " 'White/Liver Tick' 'Yellow/Cream' 'Liver/Chocolate' 'Brown/Brown Brindle'\n",
      " 'Brown/Brown Tabby' 'Yellow/Orange Tabby' 'Green/Black'\n",
      " 'Tricolor/Brown Brindle' 'Chocolate/Chocolate' 'White/Fawn'\n",
      " 'Blue Smoke/Gray' 'Blue/Green' 'White/Lilac Point' 'Cream/Yellow'\n",
      " 'Cream/Brown Merle' 'Red Merle/Brown Merle' 'Brown Merle/Brown Tabby'\n",
      " 'Torbie/Black' 'Black Tabby/Gray Tabby' 'Calico/Orange'\n",
      " 'Brown Tiger/Brown' 'White/Silver Tabby' 'Cream Tabby/Orange'\n",
      " 'Blue Tabby/Buff' 'Torbie/Silver Tabby' 'Lynx Point/Blue'\n",
      " 'Cream/Blue Point' 'Gray Tabby/Orange' 'Tortie/Tortie' 'Seal Point/Buff'\n",
      " 'Black Brindle/Black' 'Calico Point/Gray' 'Seal Point/Cream'\n",
      " 'Blue Point/Cream' 'White/Green' 'Tortie Point/Blue' 'Blue Tick/Tricolor'\n",
      " 'Brown Tabby/Agouti' 'Red Tick/Brown Brindle' 'Cream Tabby/Orange Tabby'\n",
      " 'White/Black Tiger' 'Gray Tabby/Gray' 'Silver Lynx Point/White'\n",
      " 'Gold/Gray' 'Brown/Black Brindle' 'Black Tiger' 'Tricolor/Cream'\n",
      " 'Gray/Green' 'Lilac Point/Black' 'Brown Tabby/Calico'\n",
      " 'Brown Brindle/Tricolor' 'Yellow/Green' 'Blue Merle/Gray'\n",
      " 'Gray/Blue Merle' 'Liver/Liver Tick' 'Black/Fawn' 'Brown Tabby/Silver'\n",
      " 'Brown Brindle/Liver Tick' 'Lilac Point/Gray' 'Green/Silver'\n",
      " 'Tricolor/Red' 'Brown Tabby/Lynx Point' 'Agouti/Cream' 'Tortie/Gray'\n",
      " 'Buff/Cream' 'Yellow/Brown' 'Yellow/Red' 'Lynx Point/Gray'\n",
      " 'Red/Brown Brindle' 'Green/Red' 'Cream/Tricolor'\n",
      " 'Black Brindle/Brown Brindle' 'Brown/Liver' 'Tan/Fawn' 'Yellow/Gray'\n",
      " 'Tricolor/Gray' 'Tan/Brown Brindle' 'Calico Point/Lynx Point'\n",
      " 'Black Brindle/Tan' 'Orange Tiger' 'White/Agouti' 'White/Tortie Point'\n",
      " 'Lynx Point/Cream' 'Cream/Blue' 'Brown Merle/Chocolate' 'Gray/Gray Tabby'\n",
      " 'Brown/Black Smoke' 'Fawn/Cream' 'Red Tick/Tricolor' 'White/Blue Tiger'\n",
      " 'Chocolate/Blue Tick' 'Tan/Chocolate Point' 'Black Smoke/Black Tabby'\n",
      " 'Tan/Red Merle' 'Brown/Fawn' 'Gray/Fawn' 'Blue Tabby/Tortie'\n",
      " 'Brown/Orange' 'Tricolor/Red Tick' 'Tortie Point/Seal Point'\n",
      " 'Tricolor/Blue Tick' 'Chocolate/Fawn' 'Cream Tiger/Brown Tabby'\n",
      " 'Blue Tabby/Brown' 'Brown/Gold' 'Silver/Silver Tabby'\n",
      " 'Chocolate/Seal Point' 'Chocolate Point/Cream' 'Tortie/Gold' 'Cream/Gold'\n",
      " 'Brown/Seal Point' 'Liver/Blue' 'Brown Brindle/Black Brindle'\n",
      " 'Brown Brindle/Gray' 'Brown Brindle/Brown Merle' 'White/Gray Tiger'\n",
      " 'Calico/Gray' 'Red Merle/Brown' 'Blue/Blue Merle' 'Blue/Gold'\n",
      " 'Tan/Blue Tick' 'Blue/Fawn' 'Yellow Brindle/Black'\n",
      " 'Blue Point/Lynx Point' 'Brown Tiger/Cream' 'Liver Tick/Brown'\n",
      " 'Orange/Tricolor' 'Brown Tabby/Tan' 'Buff/Red Tick' 'Tricolor/Fawn'\n",
      " 'Black Tabby/Black Smoke' 'Blue/Blue Tick' 'Cream/Brown Tabby'\n",
      " 'Cream/Cream' 'Lynx Point/Blue Point' 'White/Gold' 'Buff/Blue Merle'\n",
      " 'Orange Tabby/Tan' 'Chocolate/Gray' 'Black Tabby/Brown'\n",
      " 'Brown Brindle/Chocolate' 'Gray Tabby/Brown' 'Blue Tabby/Black'\n",
      " 'Black Tabby/Gray' 'Yellow/Blue' 'Gray Tabby/Tan' 'Silver/Gray Tabby'\n",
      " 'Tortie/Blue Merle' 'Seal Point/Silver' 'Red Merle/Red Tick'\n",
      " 'Black Brindle/Yellow' 'Blue Tabby/Brown Tabby' 'Torbie/Orange'\n",
      " 'Blue Smoke/Tan' 'Fawn/Yellow' 'Cream/Green' 'Blue Tiger/Black'\n",
      " 'Brown Tiger/Black' 'Brown Merle/Brown Merle' 'Blue/Black Brindle'\n",
      " 'Blue Merle/Brown Merle' 'Brown/Brown Tiger' 'Brown Tabby/Gold' 'Ruddy'\n",
      " 'Black Brindle/Blue Tick' 'Tricolor/Tortie' 'Yellow/Yellow'\n",
      " 'Brown Tabby/Red' 'Agouti/Gold' 'Tricolor/Orange' 'Brown Tabby/Liver'\n",
      " 'Cream/Chocolate' 'Gray/Calico' 'Black/Calico']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "for col in df.columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    print(df[col].unique())\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa2b42e-45dd-4264-bf38-67c984ff0618",
   "metadata": {},
   "source": [
    "**1.2 Data Types:** All the columns are 'object's, probably because the data isn't cleaned. That said, based on head and the unique values printing that I did: Animal ID is a string; Date of Birth is a Date string (needs to be parsed into a date from a string though); Name is  a string, DateTime is a date time string(a string that needs to be parsed, or an actual DateTime). MonthYear is a date string. OutcomeType, OutcomeSubtype, Animal Type, Breed, and Color are all categorical data that can be onehot encoded. Finally, Age upon Outcome seems to be a descriptive string of the age as a integer of days, weeks, months, or years.\n",
    "I'm going to clean up all this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a7d611-215c-4035-be67-c17649d01e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Breed', axis=1).drop('Name', axis=1).drop('Outcome Subtype', axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8701ee4d-f936-4c6d-b4cb-f95d81bc353f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df['MonthYear'].notna() & df['DateTime'].isna()\n",
    "has_missing = mask.any()\n",
    "has_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d517e498-8fcd-4a8b-8fad-f2167370a679",
   "metadata": {},
   "source": [
    "I wanted to make sure that there weren't any rows where MonthYear was present but DateTime was not. Now I can drop the MonthYear column since it's redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024b9c23-b907-4337-91ac-04d6575b6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('MonthYear', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18760725-c56e-4570-b9b6-23c8a3cda065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Outcome Type'].isin(['Transfer', 'Adoption'])]\n",
    "df['Outcome Type'] = df['Outcome Type'].map({'Transfer': 0, 'Adoption': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a11a4a6-0049-45b4-aed8-a35c608e7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portion Sex upon Outcome Unknown: 3.89% of total\n"
     ]
    }
   ],
   "source": [
    "row_count = len(df)\n",
    "\n",
    "num_unknown_sex = (df['Sex upon Outcome'] == 'Unknown').sum()\n",
    "portion_us_unknown = num_unknown_sex / row_count\n",
    "\n",
    "print(f\"Portion Sex upon Outcome Unknown: {portion_us_unknown:.2%} of total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b356d28-12f8-4ed0-93de-3546c3cce57f",
   "metadata": {},
   "source": [
    "I'm OK swapping out 'Unknown' Sex upon Outcome values for the most frequent value (mode), but I don't want to replace Invalid Outcome Subtypes with some other value since that would have a massive impact on the data. Instead, I'll leave \"NaN\" as a legitimate category to onehot encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8df1eb-4204-430e-b0f6-89fa8a6f8ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dob = df['Date of Birth'].apply(lambda x: isinstance(x, str) and x.strip() != \"\")\n",
    "valid_dt = df['DateTime'].apply(lambda x: isinstance(x, str) and x.strip() != \"\")\n",
    "both_valid = valid_dob & valid_dt\n",
    "both_valid.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1d41c-b48f-44e4-8d24-7d2286fabdc4",
   "metadata": {},
   "source": [
    "Since all of my data has valid DoBs and DateTimes, I can use them to calculate an 'Age entered shelter' in days and a 'Duration in shelter' in days\n",
    "I'm going to transform, add, and remove date-related features into data I find more interesting/revealing than just arbitrary dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f61e41b-ba85-492a-934d-69ead86b43c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "admitted_to_shelter = df['DateTime'].astype(str).str.strip()\n",
    "parsed_admitted_to_shelter = pd.to_datetime(admitted_to_shelter, format=\"%Y-%m-%dT%H:%M:%S\", errors='coerce').dt.tz_localize(None)\n",
    "parsed_admitted_to_shelter = parsed_admitted_to_shelter.fillna(pd.to_datetime(admitted_to_shelter, errors=\"coerce\").dt.tz_localize(None))\n",
    "df['DateTime Admitted to Shelter'] = parsed_admitted_to_shelter\n",
    "print(df['DateTime Admitted to Shelter'].isna().mean())\n",
    "df = df.drop('Date of Birth', axis=1).drop('DateTime', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6397a06-d024-4172-a4ed-b54657a13e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_duration(s: str) -> int:\n",
    "    s = s.strip().lower()\n",
    "    match = re.fullmatch(r\"(\\d+)\\s*(day|days|week|weeks|month|months|year|years)\", s)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid duration format: {s}\")\n",
    "    unit_to_days = {\n",
    "        \"day\": 1, \"days\": 1,\n",
    "        \"week\": 7, \"weeks\": 7,\n",
    "        \"month\": 30, \"months\": 30,\n",
    "        \"year\": 365, \"years\": 365,\n",
    "    }\n",
    "    return int(match.group(1)) * unit_to_days[match.group(2)]\n",
    "df['Age (days) upon Outcome'] = df['Age upon Outcome'].apply(parse_duration)\n",
    "print(df['Age (days) upon Outcome'].isna().mean())\n",
    "df = df.drop('Age upon Outcome', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41a229df-f3dd-4fce-a05c-e745f8bd7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weekday Entered Shelter'] = df['DateTime Admitted to Shelter'].dt.weekday\n",
    "df['Month Entered Shelter'] = df['DateTime Admitted to Shelter'].dt.month\n",
    "df = df.drop('DateTime Admitted to Shelter', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f394e6c-7214-4359-b494-22b603d33fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4449571723859138\n",
      "0.027191530581891128\n",
      "0.0030661978384067977\n"
     ]
    }
   ],
   "source": [
    "df['Color'] = df['Color'].astype(str).str.strip().str.lower().str.replace(r'\\s+', ' ', regex=True)\n",
    "print(df['Color'].apply(lambda x: 'white' in x).mean())\n",
    "print(df['Color'].apply(lambda x: 'cream' in x).mean())\n",
    "print(df['Color'].apply(lambda x: 'silver' in x).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9517074c-41d5-459c-b491-13306b63223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too many colors: ['blue', 'brown', 'cream']\n",
      "too many colors: ['blue', 'buff', 'cream']\n",
      "too many colors: ['blue', 'calico', 'cream']\n",
      "could not parse ruddy/cream\n",
      "failed at part ruddy\n",
      "could not parse agouti/brown tabby\n",
      "failed at part agouti\n",
      "too many patterns: ['point_siamese', 'tabby', 'tortie']\n",
      "could not parse agouti/white\n",
      "failed at part agouti\n",
      "too many colors: ['blue', 'calico', 'cream']\n",
      "too many colors: ['gray', 'lynx', 'silver']\n",
      "too many colors: ['blue', 'calico', 'cream']\n",
      "could not parse brown tabby/agouti\n",
      "failed at part agouti\n",
      "could not parse agouti/cream\n",
      "failed at part agouti\n",
      "could not parse white/agouti\n",
      "failed at part agouti\n",
      "could not parse brown tabby/agouti\n",
      "failed at part agouti\n",
      "could not parse brown tabby/agouti\n",
      "failed at part agouti\n",
      "could not parse agouti/white\n",
      "failed at part agouti\n",
      "could not parse agouti/white\n",
      "failed at part agouti\n",
      "could not parse agouti/brown tabby\n",
      "failed at part agouti\n",
      "could not parse agouti/gold\n",
      "failed at part agouti\n",
      "0.9950422174254616\n"
     ]
    }
   ],
   "source": [
    "known_colors = ['brown', 'fawn', 'flame', 'lilac', 'seal', 'lynx', 'buff', 'apricot', 'white', 'calico', 'tan', 'black', 'cream', 'orange', 'gray', 'gold', 'red', 'yellow', 'blue', 'chocolate', 'pink', 'tricolor', 'silver', 'green']\n",
    "known_patterns = ['tabby', 'brindle', 'tiger', 'point', 'smoke', 'tick', 'merle', 'sable_burmese', 'point_siamese', 'torbie', 'tortie']\n",
    "def coerce_to_slashes(x: str) -> str:\n",
    "    if x.count('/') == 3:\n",
    "        return x\n",
    "    if 'liver' in x:\n",
    "        return x\n",
    "    if x in known_colors:\n",
    "        return f'{x}/{x}/none/none'\n",
    "    if x in known_patterns:\n",
    "        return f'none/none/{x}/{x}'\n",
    "    adjusted = x.replace('sable', 'sable_burmese').replace('point', 'point_siamese').replace('tricolor', 'calico')\n",
    "    hardcoded_outputs = {\n",
    "        'blue/cream/white': 'blue/white/none/none',\n",
    "        'lynx/point_siamese/silver/white': 'lynx/white/none/none',\n",
    "    }\n",
    "    if ' ' in x or '/' in adjusted:\n",
    "        parts = re.split(r'[ /]', adjusted)\n",
    "        parts.sort()\n",
    "        parts_ordered = '/'.join(parts)\n",
    "        if parts_ordered in hardcoded_outputs:\n",
    "            return hardcoded_outputs[parts_ordered]\n",
    "        colors = []\n",
    "        patterns = []\n",
    "        could_parse=True\n",
    "        for part in parts:\n",
    "            if part in known_colors:\n",
    "                if part not in colors:\n",
    "                    colors.append(part)\n",
    "            elif part in known_patterns:\n",
    "                if part not in patterns:\n",
    "                    patterns.append(part)\n",
    "            else:\n",
    "                print(f'could not parse {x}')\n",
    "                print(f'failed at part {part}')\n",
    "                could_parse=False\n",
    "                break\n",
    "        if could_parse:\n",
    "            if len(colors) == 0:\n",
    "                colors = ['none', 'none']\n",
    "            elif len(colors) == 1:\n",
    "                colors.append(colors[0])\n",
    "            elif len(colors) > 2:\n",
    "                print(f'too many colors: {colors}')\n",
    "                return x\n",
    "            if len(patterns) == 0:\n",
    "                patterns = ['none', 'none']\n",
    "            elif len(patterns) == 1:\n",
    "                patterns.append(patterns[0])\n",
    "            elif len(patterns) > 2:\n",
    "                print(f'too many patterns: {patterns}')\n",
    "                return x\n",
    "            return '/'.join(colors + patterns)\n",
    "    return x\n",
    "df['Color'] = df['Color'].apply(coerce_to_slashes)\n",
    "print(df['Color'].apply(lambda x: x.count('/') == 3).mean())\n",
    "df = df[df['Color'].apply(lambda x: x.count('/') == 3)]\n",
    "df['ColorA'] = df['Color'].apply(lambda x: x.split('/')[0])\n",
    "df['ColorB'] = df['Color'].apply(lambda x: x.split('/')[1])\n",
    "df['PatternA'] = df['Color'].apply(lambda x: x.split('/')[2])\n",
    "df['PatternB'] = df['Color'].apply(lambda x: x.split('/')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbe3b198-d4ed-4318-90d0-937c262a41f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal ID</th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Animal Type</th>\n",
       "      <th>Sex upon Outcome</th>\n",
       "      <th>Age (days) upon Outcome</th>\n",
       "      <th>ColorA</th>\n",
       "      <th>ColorB</th>\n",
       "      <th>PatternA</th>\n",
       "      <th>PatternB</th>\n",
       "      <th>Weekday_Entered_Shelter_sin</th>\n",
       "      <th>Weekday_Entered_Shelter__cos</th>\n",
       "      <th>Month_Entered_Shelter_sin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A680855</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>black</td>\n",
       "      <td>yellow</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A680857</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>black</td>\n",
       "      <td>yellow</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A680858</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>black</td>\n",
       "      <td>yellow</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A680859</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>black</td>\n",
       "      <td>yellow</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A680860</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>black</td>\n",
       "      <td>yellow</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animal ID  Outcome Type Animal Type Sex upon Outcome  \\\n",
       "0   A680855             0        Bird          Unknown   \n",
       "1   A680857             0        Bird          Unknown   \n",
       "2   A680858             0        Bird          Unknown   \n",
       "3   A680859             0        Bird          Unknown   \n",
       "4   A680860             0        Bird          Unknown   \n",
       "\n",
       "   Age (days) upon Outcome ColorA  ColorB PatternA PatternB  \\\n",
       "0                       14  black  yellow     none     none   \n",
       "1                       14  black  yellow     none     none   \n",
       "2                       14  black  yellow     none     none   \n",
       "3                       14  black  yellow     none     none   \n",
       "4                       14  black  yellow     none     none   \n",
       "\n",
       "   Weekday_Entered_Shelter_sin  Weekday_Entered_Shelter__cos  \\\n",
       "0                     0.781831                       0.62349   \n",
       "1                     0.781831                       0.62349   \n",
       "2                     0.781831                       0.62349   \n",
       "3                     0.781831                       0.62349   \n",
       "4                     0.781831                       0.62349   \n",
       "\n",
       "   Month_Entered_Shelter_sin  \n",
       "0                       -1.0  \n",
       "1                       -1.0  \n",
       "2                       -1.0  \n",
       "3                       -1.0  \n",
       "4                       -1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['Weekday_Entered_Shelter_sin'] = np.sin(2 * np.pi * df['Weekday Entered Shelter'] / 7)\n",
    "df['Weekday_Entered_Shelter__cos'] = np.cos(2 * np.pi * df['Weekday Entered Shelter'] / 7)\n",
    "df['Month_Entered_Shelter_sin'] = np.sin(2 * np.pi * df['Month Entered Shelter'] / 12)\n",
    "df['Month_Entered_Shelter_sin'] = np.cos(2 * np.pi * df['Month Entered Shelter'] / 12)\n",
    "df = df.drop('Color', axis=1).drop('Weekday Entered Shelter', axis=1).drop('Month Entered Shelter', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c86be240-1fc9-449a-a9eb-c509bf83831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded = pd.get_dummies(df, columns=['Animal Type', 'Sex upon Outcome', 'ColorA', 'ColorB', 'PatternA', 'PatternB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c778be50-ecce-42b6-a2ca-42e01318687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = onehot_encoded.drop(columns=[\"Outcome Type\", \"Animal ID\"])\n",
    "y = onehot_encoded[\"Outcome Type\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1826f144-f33b-4530-a150-cdabec0ff9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['Age (days) upon Outcome']\n",
    "x_train[num_cols] = scaler.fit_transform(x_train[num_cols])\n",
    "x_test[num_cols] = scaler.transform(x_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25470e9b-3b4e-4635-ae0b-2144b6cfdc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred_knn = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d40c3324-7a9a-4d77-a872-2cb6214fbe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.76      9463\n",
      "           1       0.84      0.92      0.88     16629\n",
      "\n",
      "    accuracy                           0.84     26092\n",
      "   macro avg       0.84      0.81      0.82     26092\n",
      "weighted avg       0.84      0.84      0.83     26092\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"KNN\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9858efef-50e1-44aa-b072-2cb615bf48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"n_neighbors\": [3, 5, 7, 9, 11]}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring=\"f1\")\n",
    "grid.fit(x_train, y_train)\n",
    "y_pred_knn_grid = grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cbe8de5-2742-4968-9f62-cb8f0c7e91f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (GridSearchCV)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.76      9463\n",
      "           1       0.84      0.95      0.89     16629\n",
      "\n",
      "    accuracy                           0.85     26092\n",
      "   macro avg       0.86      0.81      0.83     26092\n",
      "weighted avg       0.85      0.85      0.84     26092\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN (GridSearchCV)\")\n",
    "print(classification_report(y_test, y_pred_knn_grid))\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e736a7d0-00ea-4d82-91d5-e8c0a12ffe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred_logreg = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e5e08ed-6e67-44a1-b043-bb63b78b5eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.68      0.78      9463\n",
      "           1       0.84      0.96      0.90     16629\n",
      "\n",
      "    accuracy                           0.86     26092\n",
      "   macro avg       0.87      0.82      0.84     26092\n",
      "weighted avg       0.86      0.86      0.85     26092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe0fdc-9c70-49ea-8cdc-4d9f899f0289",
   "metadata": {},
   "source": [
    "# Use of AI\n",
    "[1]. \n",
    "    Tool: ChatGPT\n",
    "\n",
    "    Prompt: \"python pandas df how can I check if there are any rows where 'MonthYear' is present but 'DateTime' is not\"\n",
    "\n",
    "    Output:\n",
    "        # Boolean mask\n",
    "        mask = df['MonthYear'].notna() & df['DateTime'].isna()\n",
    "        \n",
    "        # Check if any rows match\n",
    "        has_missing = mask.any()\n",
    "        print(has_missing)\n",
    "[2].\n",
    "    Tool: ChatGPT\n",
    "\n",
    "    Prompt: \"how to count what portion of values in 'Outcome Subtype' that are NOT non-empty strings ie they're not a string or they're nan or they're empty strings or whatever Also how to count what portion of values in 'Sex upon Outcome' are 'Unknown'\"\n",
    "\n",
    "    Output:\n",
    "        mask = ~df['Outcome Subtype'].apply(lambda x: isinstance(x, str) and x.strip() != \"\")\n",
    "\n",
    "        # Count how many\n",
    "        num_invalid = mask.sum()\n",
    "        \n",
    "        # Portion (fraction of total rows)\n",
    "        portion_invalid = num_invalid / len(df)\n",
    "        \n",
    "        print(f\"Invalid Outcome Subtype: {num_invalid} rows, {portion_invalid:.2%} of total\")\n",
    "\n",
    "        num_unknown = (df['Sex upon Outcome'] == 'Unknown').sum()\n",
    "        portion_unknown = num_unknown / len(df)\n",
    "        \n",
    "        print(f\"Unknown Sex upon Outcome: {num_unknown} rows, {portion_unknown:.2%} of total\")\n",
    "[3].\n",
    "    Tool: ChatGPT\n",
    "\n",
    "    Prompt: \"python parse mm/dd/yy string into datetime and also parse strings like 2014-06-10T00:00:00-05:00 into datetime Also, the mm in the first one might not have leading zeros\"\n",
    "\n",
    "    Output:\n",
    "        import pandas as pd\n",
    "\n",
    "        dates = [\n",
    "            \"6/3/14\",               # mm/dd/yy without leading zeros\n",
    "            \"12/25/20\",             # mm/dd/yy with leading zeros\n",
    "            \"2014-06-10T00:00:00-05:00\"  # ISO 8601 with timezone\n",
    "        ]\n",
    "        \n",
    "        # Parse into datetime\n",
    "        parsed = pd.to_datetime(dates, errors=\"coerce\")\n",
    "        \n",
    "        print(parsed)\n",
    "[4].\n",
    "    Tool: ChatGPT\n",
    "    \n",
    "    Prompt: \"write a python parse function that takes inputs like 'n days/weeks/months/years' where n can be any real nonnegative integer and days/weeks/months/years may or may not have the trailing s and converts it to a number of days\"\n",
    "\n",
    "    Output:\n",
    "        import re\n",
    "\n",
    "        def parse_duration(s: str) -> int:\n",
    "            \"\"\"\n",
    "            Parse strings like 'n day(s)/week(s)/month(s)/year(s)' into number of days.\n",
    "            n must be a nonnegative integer.\n",
    "            \n",
    "            Assumptions:\n",
    "              - 1 day = 1 day\n",
    "              - 1 week = 7 days\n",
    "              - 1 month = 30 days (approx)\n",
    "              - 1 year = 365 days (approx)\n",
    "            \"\"\"\n",
    "            if not isinstance(s, str):\n",
    "                raise ValueError(\"Input must be a string\")\n",
    "        \n",
    "            # Normalize whitespace and lowercase\n",
    "            s = s.strip().lower()\n",
    "        \n",
    "            # Regex: capture number and unit\n",
    "            match = re.fullmatch(r\"(\\d+)\\s*(day|days|week|weeks|month|months|year|years)\", s)\n",
    "            if not match:\n",
    "                raise ValueError(f\"Invalid duration format: {s}\")\n",
    "        \n",
    "            n = int(match.group(1))\n",
    "            unit = match.group(2)\n",
    "        \n",
    "            # Conversion map\n",
    "            unit_to_days = {\n",
    "                \"day\": 1, \"days\": 1,\n",
    "                \"week\": 7, \"weeks\": 7,\n",
    "                \"month\": 30, \"months\": 30,\n",
    "                \"year\": 365, \"years\": 365,\n",
    "            }\n",
    "        \n",
    "            return n * unit_to_days[unit]\n",
    "[5].\n",
    "    Tool: ChatGPT\n",
    "    Prompt: \"how to make a onehot encoding from a sorted list of categorical vars and then onehot encode categorical columns in a df (they are already sanitized strings)\"\n",
    "    Output:\n",
    "        import pandas as pd\n",
    "\n",
    "        cats = [\"dog\", \"cat\", \"dog\", \"bird\", \"cat\"]\n",
    "        \n",
    "        # Sorted unique categories\n",
    "        unique_cats = sorted(set(cats))\n",
    "        \n",
    "        # One-hot encode\n",
    "        onehot = pd.get_dummies(cats, columns=None)\n",
    "        print(onehot)\n",
    "[6].\n",
    "    Tool: ChatGPT\n",
    "    Prompt: should I make weekday and month onehot vars?\n",
    "    Output:\n",
    "        (It yapped about onehot vs numeric but I got real interested when it suggested cyclical encoding)\n",
    "        import numpy as np\n",
    "\n",
    "        # Weekday 0=Mon, 6=Sun\n",
    "        df[\"Weekday_sin\"] = np.sin(2 * np.pi * df[\"Weekday Entered Shelter\"] / 7)\n",
    "        df[\"Weekday_cos\"] = np.cos(2 * np.pi * df[\"Weekday Entered Shelter\"] / 7)\n",
    "        \n",
    "        # Month 1-12\n",
    "        df[\"Month_sin\"] = np.sin(2 * np.pi * (df[\"Month Entered Shelter\"]-1) / 12)\n",
    "        df[\"Month_cos\"] = np.cos(2 * np.pi * (df[\"Month Entered Shelter\"]-1) / 12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
